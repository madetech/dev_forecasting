{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import data\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: As there are relatively few training examples (1677) compared to the number of variables, we'll need to be aware of overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chck nulls\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a baseline model (LGBM Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing id and target from training set\n",
    "features = list(train.columns)\n",
    "features.remove('id')\n",
    "features.remove('Attrition')\n",
    "\n",
    "target = 'Attrition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  encoding string fields to integers\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = list((train.dtypes[train.dtypes == 'object']).index)\n",
    "string_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying encoding\n",
    "label_encoder = MultiColumnLabelEncoder(columns=string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = label_encoder.fit_transform(train)\n",
    "test = label_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "scores = []\n",
    "\n",
    "'''\n",
    "As our target classes are imbalanced, StratifiedKFold ensures each fold has a good representation of all classes.\n",
    "This helps to avoid over-representing one class in training and under-representing another in testing.\n",
    "'''\n",
    "kf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for train_index, val_index in kf.split(train, y=train['Attrition']):\n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "    \n",
    "    X_train = lgbm.Dataset(X_train)\n",
    "    y_train = lgbm.Dataset(y_train)\n",
    "\n",
    "    clf = LGBMClassifier(n_estimators=150, categorical_feature=[1, 3, 6, 9, 13, 15, 19, 20, 33], metric='auc')\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    preds = clf.predict_proba(X_val)\n",
    "    \n",
    "    clfs.append(clf)\n",
    "    scores.append(roc_auc_score(y_val, preds[:, 1]))\n",
    "print(f'mean score across all folds: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which variables have most significance:\n",
    "for i in clf.feature_importances_.argsort()[::-1]:\n",
    "    print(features[i], clf.feature_importances_[i]/clf.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly employee pay has the greatest impact on our model, along with age and commute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we include CatBoostClassifier, another gradient boosting algorithm for classification before ensembling our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "scores = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "for train_index, val_index in kf.split(train, y=train['Attrition']):\n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "\n",
    "    clf = CatBoostClassifier(iterations=200)\n",
    "    clf.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
    "    \n",
    "    preds = clf.predict_proba(X_val.values)[:, 1]\n",
    "    clfs.append(clf)\n",
    "    scores.append(roc_auc_score(y_val, preds))\n",
    "print(f'mean auc across all folds: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying prediction to test set \n",
    "test_preds = []\n",
    "\n",
    "for clf in clfs:\n",
    "    preds = clf.predict_proba(test[features].values)\n",
    "    test_preds.append(preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mean of predictions\n",
    "test_preds = np.stack(test_preds).mean(0)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data={'id': test.id, 'Attrition': test_preds})\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('..data/predicition.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('dev_forecasting': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95f874259b399d5e99c8ccba34786e9d8e85c53fc31530100ae90ec4fab5abe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
